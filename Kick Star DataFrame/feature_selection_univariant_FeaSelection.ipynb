{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ks=pd.read_csv('G:/MINE/SUB/Thesis/kaggle/6.Feature Engineering/DataSet/ks-projects-201801.csv',parse_dates=['deadline','launched'])\n",
    "ks=ks.query(\"state!='live'\")\n",
    "ks=ks.assign(outcome=(ks.state=='successful').astype(int))\n",
    "ks=ks.assign(hour=ks.launched.dt.hour,\n",
    "            day=ks.launched.dt.day,\n",
    "            month=ks.launched.dt.month,\n",
    "            year= ks.launched.dt.year)\n",
    "num_col=['goal','hour','day','month','year','outcome']\n",
    "cat_col=['category','currency','country']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "encode=ks[cat_col].apply(encoder.fit_transform)\n",
    "baseline=ks[num_col].join(encode)\n",
    "import itertools\n",
    "interaction=pd.DataFrame(index=ks.index)\n",
    "for col1,col2 in itertools.combinations(cat_col,2):\n",
    "    col_name=col1+'_'+col2\n",
    "    col_value=ks[col1].map(str)+'_'+ks[col2].map(str)\n",
    "    label_encoder=LabelEncoder()\n",
    "    interaction[col_name]=label_encoder.fit_transform(col_value)\n",
    "\n",
    "interBaseline=baseline.join(interaction)\n",
    "interBaseline.head()\n",
    "release=pd.Series(ks.index,index=ks.launched,name='count_7days').sort_index()\n",
    "count_7days=release.rolling('7d').count()-1\n",
    "count_7days.index=release.values\n",
    "count_7days=count_7days.reindex(ks.index)\n",
    "cout_inter_baseline=interBaseline.join(count_7days)\n",
    "sameProject=pd.DataFrame(ks[['category','launched']],index=ks.index).sort_values('launched')\n",
    "def time_difference(series):\n",
    "    return series.diff().dt.total_seconds()/3600\n",
    "timedeltas=sameProject.groupby('category').transform(time_difference)\n",
    "timedeltas=timedeltas.fillna(timedeltas.max())\n",
    "final_baseline=cout_inter_baseline.join(timedeltas.rename({'launched':'time_since_last_Project'},axis=1))\n",
    "def make_split(df,fraction=.1):\n",
    "    size=int(len(df)*fraction)\n",
    "    train=df[:-2*size]\n",
    "    valid=df[-2*size:-size]\n",
    "    test=df[-size:]\n",
    "    return train,valid,test\n",
    "\n",
    "def train_model(train,valid,test=None,feature=None):\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    if feature is None:\n",
    "        feature=train.columns.drop('outcome')\n",
    "    dtrain=lgb.Dataset(train[feature],label=train['outcome'])\n",
    "    dvalid=lgb.Dataset(valid[feature],label=valid['outcome'])\n",
    "    param={'num_leaves':64,'objective':'binary','metric':'auc','seed':7}\n",
    "    num_round=1000\n",
    "    model=lgb.train(param,dtrain,num_round,valid_sets=[dvalid],verbose_eval=False,early_stopping_rounds=20)\n",
    "    validPredict=model.predict(valid[feature])\n",
    "    print('\\n'*4)\n",
    "    print(\"wait a second to see accuracy on valid sets .. .\")\n",
    "    print(\"valid accuracy = {}\".format(roc_auc_score(valid['outcome'],validPredict)))\n",
    "    if test is not None:\n",
    "        print('wait another second to see accuracy on test set .. .')\n",
    "        print('test accuracy = {}'.format(roc_auc_score(test['outcome'],model.predict(test[feature]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 107340, number of negative: 193350\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1553\n",
      "[LightGBM] [Info] Number of data points in the train set: 300690, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.356979 -> initscore=-0.588501\n",
      "[LightGBM] [Info] Start training from score -0.588501\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wait a second to see accuracy on valid sets .. .\n",
      "valid accuracy = 0.7466774415346332\n",
      "wait another second to see accuracy on test set .. .\n",
      "test accuracy = 0.746659055391359\n"
     ]
    }
   ],
   "source": [
    "train,valid,test=make_split(final_baseline)\n",
    "train_model(train,valid,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.015e+03, 5.000e+00, 9.000e+00, 1.800e+01, 1.409e+03],\n",
       "       [2.017e+03, 1.300e+01, 2.200e+01, 3.100e+01, 9.570e+02],\n",
       "       [2.013e+03, 1.300e+01, 2.200e+01, 3.100e+01, 7.390e+02],\n",
       "       ...,\n",
       "       [2.011e+03, 1.300e+01, 2.200e+01, 3.100e+01, 5.150e+02],\n",
       "       [2.015e+03, 1.000e+00, 3.000e+00, 2.000e+00, 1.306e+03],\n",
       "       [2.013e+03, 1.300e+01, 2.200e+01, 3.100e+01, 1.084e+03]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_classif #ANOVA f value \n",
    "feature_col=final_baseline.columns.drop('outcome')\n",
    "train,valid,test=make_split(final_baseline)\n",
    "selector=SelectKBest(f_classif,k=5)\n",
    "x_uni=selector.fit_transform(train[feature_col],train['outcome'])\n",
    "x_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>currency</th>\n",
       "      <th>country</th>\n",
       "      <th>category_currency</th>\n",
       "      <th>category_country</th>\n",
       "      <th>currency_country</th>\n",
       "      <th>count_7days</th>\n",
       "      <th>time_since_last_Project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>907.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   goal  hour  day  month    year  category  currency  country  \\\n",
       "0   0.0   0.0  0.0    0.0  2015.0       0.0       5.0      9.0   \n",
       "1   0.0   0.0  0.0    0.0  2017.0       0.0      13.0     22.0   \n",
       "2   0.0   0.0  0.0    0.0  2013.0       0.0      13.0     22.0   \n",
       "3   0.0   0.0  0.0    0.0  2012.0       0.0      13.0     22.0   \n",
       "4   0.0   0.0  0.0    0.0  2015.0       0.0      13.0     22.0   \n",
       "5   0.0   0.0  0.0    0.0  2016.0       0.0      13.0     22.0   \n",
       "6   0.0   0.0  0.0    0.0  2014.0       0.0      13.0     22.0   \n",
       "\n",
       "   category_currency  category_country  currency_country  count_7days  \\\n",
       "0                0.0               0.0              18.0       1409.0   \n",
       "1                0.0               0.0              31.0        957.0   \n",
       "2                0.0               0.0              31.0        739.0   \n",
       "3                0.0               0.0              31.0        907.0   \n",
       "4                0.0               0.0              31.0       1429.0   \n",
       "5                0.0               0.0              31.0       1284.0   \n",
       "6                0.0               0.0              31.0       1119.0   \n",
       "\n",
       "   time_since_last_Project  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "5                      0.0  \n",
       "6                      0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_feature=pd.DataFrame(selector.inverse_transform(x_uni),index=train.index,columns=feature_col)\n",
    "select_feature.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'currency', 'country', 'currency_country', 'count_7days'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_col=select_feature.columns[select_feature.var()!=0]\n",
    "selected_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_col=list(selected_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_col.append('outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year', 'currency', 'country', 'currency_country', 'count_7days', 'outcome']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(selected_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_train=train[selected_col]\n",
    "uni_valid=valid[selected_col]\n",
    "uni_test=test[selected_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 107340, number of negative: 193350\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 335\n",
      "[LightGBM] [Info] Number of data points in the train set: 300690, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.356979 -> initscore=-0.588501\n",
      "[LightGBM] [Info] Start training from score -0.588501\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wait a second to see accuracy on valid sets .. .\n",
      "valid accuracy = 0.6010188249130639\n",
      "wait another second to see accuracy on test set .. .\n",
      "test accuracy = 0.6038882667359431\n"
     ]
    }
   ],
   "source": [
    "train_model(uni_train,uni_valid,uni_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SelectKBest in module sklearn.feature_selection._univariate_selection:\n",
      "\n",
      "class SelectKBest(_BaseFilter)\n",
      " |  SelectKBest(score_func=<function f_classif at 0x0000020ABDB63790>, *, k=10)\n",
      " |  \n",
      " |  Select features according to the k highest scores.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <univariate_feature_selection>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  score_func : callable\n",
      " |      Function taking two arrays X and y, and returning a pair of arrays\n",
      " |      (scores, pvalues) or a single array with scores.\n",
      " |      Default is f_classif (see below \"See also\"). The default function only\n",
      " |      works with classification tasks.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  k : int or \"all\", optional, default=10\n",
      " |      Number of top features to select.\n",
      " |      The \"all\" option bypasses selection, for use in a parameter search.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  scores_ : array-like of shape (n_features,)\n",
      " |      Scores of features.\n",
      " |  \n",
      " |  pvalues_ : array-like of shape (n_features,)\n",
      " |      p-values of feature scores, None if `score_func` returned only scores.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_digits\n",
      " |  >>> from sklearn.feature_selection import SelectKBest, chi2\n",
      " |  >>> X, y = load_digits(return_X_y=True)\n",
      " |  >>> X.shape\n",
      " |  (1797, 64)\n",
      " |  >>> X_new = SelectKBest(chi2, k=20).fit_transform(X, y)\n",
      " |  >>> X_new.shape\n",
      " |  (1797, 20)\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Ties between features with equal scores will be broken in an unspecified\n",
      " |  way.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  f_classif: ANOVA F-value between label/feature for classification tasks.\n",
      " |  mutual_info_classif: Mutual information for a discrete target.\n",
      " |  chi2: Chi-squared stats of non-negative features for classification tasks.\n",
      " |  f_regression: F-value between label/feature for regression tasks.\n",
      " |  mutual_info_regression: Mutual information for a continuous target.\n",
      " |  SelectPercentile: Select features based on percentile of the highest scores.\n",
      " |  SelectFpr: Select features based on a false positive rate test.\n",
      " |  SelectFdr: Select features based on an estimated false discovery rate.\n",
      " |  SelectFwe: Select features based on family-wise error rate.\n",
      " |  GenericUnivariateSelect: Univariate feature selector with configurable mode.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SelectKBest\n",
      " |      _BaseFilter\n",
      " |      sklearn.feature_selection._base.SelectorMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, score_func=<function f_classif at 0x0000020ABDB63790>, *, k=10)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseFilter:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Run score function on (X, y) and get the appropriate features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The training input samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.feature_selection._base.SelectorMixin:\n",
      " |  \n",
      " |  get_support(self, indices=False)\n",
      " |      Get a mask, or integer index, of the features selected\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : boolean (default False)\n",
      " |          If True, the return value will be an array of integers, rather\n",
      " |          than a boolean mask.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      support : array\n",
      " |          An index that selects the retained features from a feature vector.\n",
      " |          If `indices` is False, this is a boolean array of shape\n",
      " |          [# input features], in which an element is True iff its\n",
      " |          corresponding feature is selected for retention. If `indices` is\n",
      " |          True, this is an integer array of shape [# output features] whose\n",
      " |          values are indices into the input feature vector.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Reverse the transformation operation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_original_features]\n",
      " |          `X` with columns of zeros inserted where features would have\n",
      " |          been removed by :meth:`transform`.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Reduce X to the selected features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples with only the selected features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features)\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,), default=None\n",
      " |          Target values.\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
