{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ks=pd.read_csv('G:/MINE/SUB/Thesis/kaggle/6.Feature Engineering/DataSet/ks-projects-201801.csv',parse_dates=['deadline','launched'])\n",
    "ks=ks.query(\"state!='live'\")\n",
    "ks=ks.assign(outcome=(ks.state=='successful').astype(int))\n",
    "ks=ks.assign(hour=ks.launched.dt.hour,\n",
    "            day=ks.launched.dt.day,\n",
    "            month=ks.launched.dt.month,\n",
    "            year= ks.launched.dt.year)\n",
    "num_col=['goal','hour','day','month','year','outcome']\n",
    "cat_col=['category','currency','country']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "encode=ks[cat_col].apply(encoder.fit_transform)\n",
    "baseline=ks[num_col].join(encode)\n",
    "import itertools\n",
    "interaction=pd.DataFrame(index=ks.index)\n",
    "for col1,col2 in itertools.combinations(cat_col,2):\n",
    "    col_name=col1+'_'+col2\n",
    "    col_value=ks[col1].map(str)+'_'+ks[col2].map(str)\n",
    "    label_encoder=LabelEncoder()\n",
    "    interaction[col_name]=label_encoder.fit_transform(col_value)\n",
    "\n",
    "interBaseline=baseline.join(interaction)\n",
    "interBaseline.head()\n",
    "release=pd.Series(ks.index,index=ks.launched,name='count_7days').sort_index()\n",
    "count_7days=release.rolling('7d').count()-1\n",
    "count_7days.index=release.values\n",
    "count_7days=count_7days.reindex(ks.index)\n",
    "cout_inter_baseline=interBaseline.join(count_7days)\n",
    "sameProject=pd.DataFrame(ks[['category','launched']],index=ks.index).sort_values('launched')\n",
    "def time_difference(series):\n",
    "    return series.diff().dt.total_seconds()/3600\n",
    "timedeltas=sameProject.groupby('category').transform(time_difference)\n",
    "timedeltas=timedeltas.fillna(timedeltas.max())\n",
    "final_baseline=cout_inter_baseline.join(timedeltas.rename({'launched':'time_since_last_Project'},axis=1))\n",
    "def make_split(df,fraction=.1):\n",
    "    size=int(len(df)*fraction)\n",
    "    train=df[:-2*size]\n",
    "    valid=df[-2*size:-size]\n",
    "    test=df[-size:]\n",
    "    return train,valid,test\n",
    "\n",
    "def train_model(train,valid,test=None,feature=None):\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    if feature is None:\n",
    "        feature=train.columns.drop('outcome')\n",
    "    dtrain=lgb.Dataset(train[feature],label=train['outcome'])\n",
    "    dvalid=lgb.Dataset(valid[feature],label=valid['outcome'])\n",
    "    param={'num_leaves':64,'objective':'binary','metric':'auc','seed':7}\n",
    "    num_round=1000\n",
    "    model=lgb.train(param,dtrain,num_round,valid_sets=[dvalid],verbose_eval=False,early_stopping_rounds=20)\n",
    "    validPredict=model.predict(valid[feature])\n",
    "    print('\\n'*4)\n",
    "    print(\"wait a second to see accuracy on valid sets .. .\")\n",
    "    print(\"valid accuracy = {}\".format(roc_auc_score(valid['outcome'],validPredict)))\n",
    "    if test is not None:\n",
    "        print('wait another second to see accuracy on test set .. .')\n",
    "        print('test accuracy = {}'.format(roc_auc_score(test['outcome'],model.predict(test[feature]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+03, 1.20e+01, 1.10e+01, ..., 1.08e+02, 5.00e+00, 9.00e+00],\n",
       "       [3.00e+04, 4.00e+00, 2.00e+00, ..., 9.30e+01, 1.30e+01, 2.20e+01],\n",
       "       [4.50e+04, 0.00e+00, 1.20e+01, ..., 9.30e+01, 1.30e+01, 2.20e+01],\n",
       "       ...,\n",
       "       [2.50e+03, 0.00e+00, 3.00e+00, ..., 1.04e+02, 1.30e+01, 2.20e+01],\n",
       "       [2.60e+03, 2.10e+01, 2.30e+01, ..., 5.80e+01, 1.00e+00, 3.00e+00],\n",
       "       [2.00e+04, 1.60e+01, 4.00e+00, ..., 5.20e+01, 1.30e+01, 2.20e+01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "train,valid,test=make_split(final_baseline)\n",
    "feature_col=baseline.columns.drop('outcome')\n",
    "x_l,y_l=train[feature_col],train['outcome']\n",
    "\n",
    "logistic=LogisticRegression(C=1,penalty='l1',solver='liblinear',random_state=7).fit(x_l,y_l)\n",
    "model=SelectFromModel(logistic,prefit=True)\n",
    "x_new=model.transform(x_l)\n",
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1000.,   12.,   11.,    8., 2015.,  108.,    5.,    9.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new[:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_feature=pd.DataFrame(model.inverse_transform(x_new),index=train.index,columns=feature_col)\n",
    "final_col=selected_feature.columns[selected_feature.var()!=0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>currency</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19500.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      goal  hour   day  month    year  category  currency  country\n",
       "0   1000.0  12.0  11.0    8.0  2015.0     108.0       5.0      9.0\n",
       "1  30000.0   4.0   2.0    9.0  2017.0      93.0      13.0     22.0\n",
       "2  45000.0   0.0  12.0    1.0  2013.0      93.0      13.0     22.0\n",
       "3   5000.0   3.0  17.0    3.0  2012.0      90.0      13.0     22.0\n",
       "4  19500.0   8.0   4.0    7.0  2015.0      55.0      13.0     22.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_col=list(final_col)\n",
    "final_col.append('outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 107340, number of negative: 193350\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 527\n",
      "[LightGBM] [Info] Number of data points in the train set: 300690, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.356979 -> initscore=-0.588501\n",
      "[LightGBM] [Info] Start training from score -0.588501\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wait a second to see accuracy on valid sets .. .\n",
      "valid accuracy = 0.7475021559270776\n",
      "wait another second to see accuracy on test set .. .\n",
      "test accuracy = 0.7475021559270776\n"
     ]
    }
   ],
   "source": [
    "final_train=train[final_col]\n",
    "final_valid=valid[final_col]\n",
    "final_test=valid[final_col]\n",
    "train_model(final_train,final_valid,final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 107340, number of negative: 193350\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1553\n",
      "[LightGBM] [Info] Number of data points in the train set: 300690, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.356979 -> initscore=-0.588501\n",
      "[LightGBM] [Info] Start training from score -0.588501\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wait a second to see accuracy on valid sets .. .\n",
      "valid accuracy = 0.7466774415346332\n",
      "wait another second to see accuracy on test set .. .\n",
      "test accuracy = 0.746659055391359\n"
     ]
    }
   ],
   "source": [
    "train_model(train,valid,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
